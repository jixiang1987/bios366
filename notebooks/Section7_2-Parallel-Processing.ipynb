{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Parallel Processing in Python\n",
      "\n",
      "An obvious way to improve the performance of Python code is to make it run in parallel. Any relatively new computer will have multiple cores, which means that several processors can operate on the same data stored on memory. However, most of the code we have written in the course so far does not take advantage of more than one of them. In addition there is now widespread availability of computing clusters, such as [those offered for use by Amazon](http://aws.amazon.com/ec2/) (Vanderbilt also has [its own cluster](http://www.accre.vanderbilt.edu)). Clusters allow several computers to work together by exchanging data over a network.\n",
      "\n",
      "Parallel computing involves breaking a task into several independent sub-tasks, distributing these sub-tasks to available processors or computers, then coordinating the execution of these tasks and combining their outputs in an appropriate way.\n",
      "\n",
      "There are several different models for parallel processing, including:\n",
      "\n",
      "* **Message passing**: processes or other program components running in parallel communicate by sending and receiving messages, which allows for easy synchronization. \n",
      "* **Multi-threading**: within a single process, some architectures allow for the existence of several \"threads\", which execute independently, though they share the memory and state of the process in which they reside. Multi-threading is good for increasing *throughput* and reducing *latency*.\n",
      "* **Task farming**: a master process delegates independent calculations to available processors (task farm), and collects their outputs when complete.\n",
      "* **Single program, multiple data (SPMD)** Probably the most common type of parallel processing, in which tasks are split up and run simultaneously on multiple processors with different input in order to obtain results faster. All tasks execute their copy of the same program simultaneously.\n",
      "* **Multiple program, multiple data (MPMD)** Like SPMD, except each task may be executing a different program."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## `multiprocessing`\n",
      "\n",
      "The simplest way (though probably not the best) for performing parallel computing in Python is via the built-in process-based library for concurrent computing, called `multiprocessing`. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import multiprocessing\n",
      "import os\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `multiprocessing` module parallelizes by launching multiple *processes*, each with a seperate interpretor. You may have already heard about *threads*. Processes and threads are not the same:\n",
      "\n",
      "* processes are independent of one another, each having their own state, memory and address spaces\n",
      "* threads share resources, and are therefore interdependent; they are subunits of the same process\n",
      "\n",
      "Since processes are independent, they now have independent Global Interpreter Locks (GILs),  its best to run multiprocessing on multiple CPUs. You can check how many you have on your machine:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "multiprocessing.cpu_count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "4"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### `Process` class\n",
      "\n",
      "The `Process` class encapsulates a task running in a process. It will usually have a `target` argument that is some callable (function/method) that is executed when the process runs, along with optional arguments that can be passed to the target.\n",
      "\n",
      "A `Process` has several methods, with some useful ones being:\n",
      "\n",
      "* `is_alive`: Returns `True` if the process is running.\n",
      "* `join`: Waits for the process to finish its work and terminate. An optional `timeout` argument can be passed.\n",
      "* `run`: When the process starts, this method is called to invoke the `target`.\n",
      "* `terminate`: Kills the process forcibly, without any cleanup.\n",
      "\n",
      "A `Process` also has several other non-callable attributes, such as `pid`, `name` and `authkey`.\n",
      "\n",
      "Here is a trivial example of using the `Process` class, showing that each has its own process ID."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "def job(n):\n",
      "    print('I am working on job {0} running on PID {1}'.format(n, os.getpid()))\n",
      "\n",
      "jobs = []\n",
      "for i in range(5):\n",
      "    p = multiprocessing.Process(target=job, args=(i,))\n",
      "    jobs.append(p)\n",
      "    p.start()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "jobs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "I am working on job 0 running on PID 47047\n",
        "I am working on job 1 running on PID 47048\n",
        "I am working on job 2 running on PID 47049\n",
        "I am working on job 3 running on PID 47050\n",
        "I am working on job 4 running on PID 47051\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "[<Process(Process-1, stopped)>,\n",
        " <Process(Process-2, stopped)>,\n",
        " <Process(Process-3, stopped)>,\n",
        " <Process(Process-4, stopped)>,\n",
        " <Process(Process-5, stopped)>]"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can easily subclass `Process` to our liking:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class FibProcess(multiprocessing.Process):\n",
      "    \n",
      "    def __init__(self, n):\n",
      "        self.n = n\n",
      "        multiprocessing.Process.__init__(self)\n",
      "        \n",
      "    def run(self):\n",
      "        a, b = 0, 1\n",
      "        for i in range(self.n):\n",
      "            a, b = b, a + b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = FibProcess(10000)\n",
      "p.start()\n",
      "print(p.pid)\n",
      "p.join()\n",
      "print(p.exitcode)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "47055\n",
        "0\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### `Queue` class\n",
      "\n",
      "Of course, despite being independent, we would like our processes to communicate with one another, for example, to share data. One way to facilitate this in `multiprocessing` is via the `Queue` class, a thread/process safe, first-in-first-out (FIFO) data structure that can store any serializable Python object.\n",
      "\n",
      "A `Queue`'s important methods include:\n",
      "\n",
      "* `put`: Adds item to `Queue`.\n",
      "* `get`: Fetchs next item from `Queue`.\n",
      "* `close`: Closes the `Queue`, preventing the addition of more data.\n",
      "* `empty`: Returns True if the `Queue` is empty.\n",
      "* `full`: Returns True if full.\n",
      "* `qsize`: Retuns approximate current number of items in `Queue`.\n",
      "\n",
      "A subclass of `Queue` is the `JoinableQueue`, which has additional methods, notably `join`, which waits until all the items have been processed, blocking the addition of new items.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from multiprocessing import Queue\n",
      "\n",
      "q = Queue()\n",
      "\n",
      "q.put(-1)\n",
      "q.put('foobar')\n",
      "q.put(5)\n",
      "\n",
      "print(q.get())\n",
      "print(q.get())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-1\n",
        "foobar\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def consumer(q):\n",
      "    while True:\n",
      "        thing = q.get()\n",
      "        if thing is None:\n",
      "            break\n",
      "        print('Consuming {}'.format(thing))\n",
      "    print(\"\\nFinished consuming\")\n",
      "    \n",
      "def producer(sequence, q):\n",
      "    for thing in sequence:\n",
      "        q.put(thing)\n",
      "        \n",
      "queue = multiprocessing.Queue()\n",
      "\n",
      "consumer_process = multiprocessing.Process(target=consumer, args=[queue])\n",
      "consumer_process.start()\n",
      "\n",
      "stuff = [42, 'foobar', True, range(5)]\n",
      "producer(stuff, queue)\n",
      "\n",
      "queue.put(None)\n",
      "consumer_process.join()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Consuming 42\n",
        "Consuming foobar\n",
        "Consuming True\n",
        "Consuming [0, 1, 2, 3, 4]\n",
        "\n",
        "Finished consuming\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Two things to be aware of:\n",
      "\n",
      "1. if you `terminate` a process that is still accessing a queue, the queue may become corrupted\n",
      "2. you should make sure that any queue to which a given process has given data is clear before joining the process, or you will get a deadlock condition\n",
      "\n",
      "### `Pool` class\n",
      "\n",
      "We often have a task that we want to split up among several worker processes in parallel. The `Pool` class creates a number of processes and the methods for passing work to them. A `Pool` has the following key methods:\n",
      "\n",
      "* `apply`: Executes a passed function in a process and returns the result.\n",
      "* `apply_async`: Same as apply, but the result is returned asynchrnously via a *callback*\n",
      "* `map`: A parallel version of `apply`, which splits an iterable of data into chunks and farms chunks out to processes.\n",
      "* `map_async`: Asynchronous `map`."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Example: parallel bootstrap\n",
      "\n",
      "As an example, we will choose a statistical computing task that is [*embarassingly parallel*](http://en.wikipedia.org/wiki/Embarrassingly_parallel). This function generates statistics of bootstrapped samples from a dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def bootstrap(data, nsamples, f):\n",
      "    boot_samples = data[np.random.randint(len(data), size=(nsamples, len(data)))]\n",
      "    return [f(s) for s in boot_samples]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pool = multiprocessing.Pool(processes=4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "some_data = np.random.poisson(4, 25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = pool.apply_async(bootstrap, (some_data, 1000, np.mean))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The result is an `ApplyResult` object:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "<multiprocessing.pool.ApplyResult at 0x10c4d6e10>"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We may then want to take the result and calculate a confidence interval based on the quantiles."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bootstrap_ci = lambda boot, alpha=0.05: (boot[np.floor((0.5*alpha)*len(boot))],\n",
      "            boot[np.floor((1.-0.5*alpha)*len(boot))])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bootstrap_ci(np.sort(result.get()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "(3.1200000000000001, 4.3600000000000003)"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Clean up\n",
      "pool.close()\n",
      "pool.join()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But, since we used `Pool.apply`, this is not a parallel task. We need to use `map`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mapped_bootstrap(n): \n",
      "    return bootstrap(some_data, n, np.mean)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pool = multiprocessing.Pool(processes=4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "map_result = pool.map_async(mapped_bootstrap, [250]*4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "map_result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "<multiprocessing.pool.MapResult at 0x10c9d3e50>"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parallel_results = map_result.get()\n",
      "[len(p) for p in parallel_results]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "[250, 250, 250, 250]"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bootstrap_ci(np.sort(np.ravel(parallel_results)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "(3.0800000000000001, 4.4000000000000004)"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pool.close()\n",
      "pool.join()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The multiprocessing package is very useful for highly parallel tasks that do not need to communicate with each other, other than when sending the initial data to the pool of processes and when and collecting the results. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## IPython parallel\n",
      "\n",
      "The IPython architecture consists of four components, which reside in the `IPython.parallel` package:\n",
      "\n",
      "1. **Engine** The IPython engine is a Python instance that accepts Python commands over a network connection.  When multiple engines are started, parallel and distributed computing becomes possible. An important property of an IPython engine is that it blocks while user code is being executed. \n",
      "\n",
      "2. **Hub** The hub keeps track of engine connections, schedulers, clients, as well as persist all task requests and results in a database for later use.\n",
      "\n",
      "3. **Schedulers** All actions that can be performed on the engine go through a Scheduler. While the engines themselves block when user code is run, the schedulers hide that from the user to provide a fully asynchronous interface to a set of engines.\n",
      "\n",
      "4. **Client** The primary object for connecting to a cluster.\n",
      "\n",
      "![IPython architecture](images/ipython_architecture.png)\n",
      "(courtesy Min Ragan-Kelley)\n",
      "\n",
      "This architecture is implemented using the \u00d8MQ messaging library and the associated Pytohn bindings in `pyzmq`.\n",
      "\n",
      "## Start your engines!\n",
      "\n",
      "In order to use IPython for parallel computing, you will need to start the IPython\n",
      "controller and two or more IPython engines. The simplest way of doing this is\n",
      "with the [clusters tab](/#tab2), or you can use the `ipcluster` command in a terminal:\n",
      "\n",
      "    $ ipcluster start --n=4\n",
      "\n",
      "This command will start 4 IPython engines on the current host, which is appropriate for many desktop multicore systems. You can also setup IPython clusters that span many nodes in a computing cluster, but this is beyond the scope of this lecture, but you can get more information from \n",
      "[the IPython.parallel docs](http://ipython.org/ipython-doc/dev/parallel/parallel_process.html)..\n",
      "\n",
      "To use the IPython cluster in our Python programs or notebooks, we start by creating an instance of `IPython.parallel.Client`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cli = Client()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This creates a client using the default profile; you can pass an optional `profile=\"my_profile\"` argument if you have a different one running.\n",
      "\n",
      "Using the `ids` attribute we can retreive a list of ids for the IPython engines in the cluster:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cli.ids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "[0, 1, 2, 3]"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can use a `DirectView` object for execution of tasks, which an be accessed simply by indexing the client:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dv0 = cli[0]\n",
      "dv0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "<DirectView 0>"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The above shows just a single engine, but we want all of them:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dview = cli[:]\n",
      "dview"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "<DirectView [0, 1, 2, 3]>"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can get a view on whatever combination of engines we want:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cli[::2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "<DirectView [0, 2]>"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cli[1::2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "<DirectView [1, 3]>"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `block` flag specifies whether to wait for the result, or return an `AsyncResult` object immediately:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dview.block = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, since we want to use IPython's parallel magic commands, we set the `DirectView` to be `active`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dview.activate()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Each of these engines are ready to execute tasks. We can selectively run code on individual engines. For example, we can simply use `os.getpid` to return the process ID that the engine is running on. Here is the notebook process:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "os.getpid()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "47030"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here is a single engine's process ID:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dv0.apply_sync(os.getpid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "47038"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And here are all the engines, run simultaneously:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dview.apply_sync(os.getpid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "[47038, 47039, 47040, 47041]"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's now consider a useful function that we might want to run in parallel. Here is a version of the approximate Bayesian computing (ABC) algorithm that we have seen in previous lectures."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "\n",
      "def abc(y, N, epsilon=[0.2, 0.8]):\n",
      "\n",
      "    trace = []\n",
      "\n",
      "    while len(trace) < N:\n",
      "\n",
      "        # Simulate from priors\n",
      "        mu = numpy.random.normal(0, 10)\n",
      "        sigma = numpy.random.uniform(0, 20)\n",
      "\n",
      "        x = numpy.random.normal(mu, sigma, 50)\n",
      "\n",
      "        #if (np.linalg.norm(y - x) < epsilon):\n",
      "        if ((abs(x.mean() - y.mean()) < epsilon[0]) &\n",
      "            (abs(x.std() - y.std()) < epsilon[1])):\n",
      "            trace.append([mu, sigma])\n",
      "\n",
      "    return trace"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = np.random.normal(4, 2, 50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's try running this on one of the cluster engines:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dv0.block = True\n",
      "dv0.apply(abc, y, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "RemoteError",
       "evalue": "NameError(global name 'numpy' is not defined)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m",
        "\u001b[0;32m<ipython-input-36-8c68243c2f97>\u001b[0m in \u001b[0;36mabc\u001b[0;34m(y, N, epsilon)\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: global name 'numpy' is not defined"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This fails with a `NameError` because NumPy has not been imported on the engine to which we sent the task. Each engine has its own namespace, so we need to import whatever modules we will need  prior to running our code:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cli[0].execute(\"import numpy\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "<AsyncResult: execute>"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dv0.apply(abc, y, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "[[3.782399224336093, 2.352941910113615],\n",
        " [3.4539665855877506, 1.2522032700642027],\n",
        " [3.3295634542213213, 2.113010934612778],\n",
        " [3.668515760053799, 1.9524596915088988],\n",
        " [3.369183052606365, 1.2714552418881175],\n",
        " [3.5601249383858686, 1.5847377302695875],\n",
        " [3.9226616401192627, 1.5288240685789978],\n",
        " [4.167498565990489, 2.3671321219381847],\n",
        " [3.0768680531499686, 2.143726374514323],\n",
        " [3.019986754009041, 1.282366648557045]]"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A more efficient way is to simultaneously import modules into the local and the engine namespaces simultaneously, using a context manager:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with dview.sync_imports():\n",
      "    import numpy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "importing numpy on engine(s)\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = dview.apply(abc, y, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Easier yet, you can use the parallel cell magic to import everywhere:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "import numpy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can also use the `require` decorator for functions that you wish to use on engines."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import require\n",
      "\n",
      "@require(\"numpy\")\n",
      "def abc(y, N, epsilon=[0.2, 0.8]):\n",
      "\n",
      "    trace = []\n",
      "\n",
      "    while len(trace) < N:\n",
      "\n",
      "        # Simulate from priors\n",
      "        mu = numpy.random.normal(0, 10)\n",
      "        sigma = numpy.random.uniform(0, 20)\n",
      "\n",
      "        x = numpy.random.normal(mu, sigma, 50)\n",
      "\n",
      "        #if (np.linalg.norm(y - x) < epsilon):\n",
      "        if ((abs(x.mean() - y.mean()) < epsilon[0]) &\n",
      "            (abs(x.std() - y.std()) < epsilon[1])):\n",
      "            trace.append([mu, sigma])\n",
      "\n",
      "    return trace"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A simple way to run code on an engine is via the `execute` method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dv0.execute('x=3')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "<AsyncResult: finished>"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dv0['x']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "3"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Data transfer\n",
      "\n",
      "We will often want to send data to our engines, or retrieve objects from them. `DirectView` has `push` and `pull` methods for achieving this.\n",
      "\n",
      "Recall that Python namespaces are just dictionaries. So, we can update an engine's namespace by pushing a dictionary:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dv0.push({'foo': -3, 'bar': np.arange(10)})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dv0.pull(('x', 'bar'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "[3, array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])]"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Additionally, `DirectView` objects also have `scatter` and `gather` methods, to distribute data among engines. `scatter` accepts any container or Numpy `array` type, while `gather` assembles the respective return objects in the Client."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Some Gaussian data\n",
      "y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "array([ 2.79022379,  3.43596291,  1.7692398 ,  5.70697304, -0.77277171,\n",
        "        4.88522089,  5.73966658,  0.73846853,  5.28613519,  3.06724312,\n",
        "        4.50886669,  6.41145773,  5.27328529,  5.36430918,  2.55736847,\n",
        "        3.5219595 ,  3.47382646,  2.03694651,  1.09331414,  2.4488314 ,\n",
        "        3.3825841 ,  1.77386663,  5.2603935 ,  5.94455855,  2.36307999,\n",
        "        3.46725586,  2.83580071,  3.67746307, -0.95944966,  3.53977832,\n",
        "        2.973732  ,  6.01003127,  3.59105   ,  3.91172605,  4.50697357,\n",
        "        5.70535512,  2.46242259,  1.96025834,  6.88912553,  5.14679456,\n",
        "        6.66645894,  0.06690179,  1.20331401,  6.50559885,  5.44151446,\n",
        "        1.9461721 ,  4.43264952,  2.62080932,  0.09201998,  4.81473745])"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Send to engines\n",
      "dview.scatter('y', y)\n",
      "dview['y']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "[array([ 2.79022379,  3.43596291,  1.7692398 ,  5.70697304, -0.77277171,\n",
        "         4.88522089,  5.73966658,  0.73846853,  5.28613519,  3.06724312,\n",
        "         4.50886669,  6.41145773,  5.27328529]),\n",
        " array([ 5.36430918,  2.55736847,  3.5219595 ,  3.47382646,  2.03694651,\n",
        "         1.09331414,  2.4488314 ,  3.3825841 ,  1.77386663,  5.2603935 ,\n",
        "         5.94455855,  2.36307999,  3.46725586]),\n",
        " array([ 2.83580071,  3.67746307, -0.95944966,  3.53977832,  2.973732  ,\n",
        "         6.01003127,  3.59105   ,  3.91172605,  4.50697357,  5.70535512,\n",
        "         2.46242259,  1.96025834]),\n",
        " array([ 6.88912553,  5.14679456,  6.66645894,  0.06690179,  1.20331401,\n",
        "         6.50559885,  5.44151446,  1.9461721 ,  4.43264952,  2.62080932,\n",
        "         0.09201998,  4.81473745])]"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Remote execution of function\n",
      "dview.execute('sum_y = sum(y)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "<AsyncResult: finished>"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Aggregation on client\n",
      "sum(dview.gather('sum_y'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "177.56950400620107"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `map` method essentially combines `scatter` and `gather` into a single call:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dview.map(lambda x: sum(x**2), np.split(y, 5))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "[150.59381377586215,\n",
        " 160.37308438275141,\n",
        " 130.22007893368664,\n",
        " 209.88036889837247,\n",
        " 171.32178464346075]"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Load balancing\n",
      "\n",
      "The `DirectView` objects we have used so far strictly allocate particular tasks to particular engines. This is often inefficient, when tasks take variable amounts of time, leaving some engines idle while some are overworked. We can use a **load balanced** view to distribute memory approximately equally among engines, to minimize idle time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lb_view = cli.load_balanced_view()\n",
      "lb_view"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "<LoadBalancedView None>"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A `LoadBalancedView`, though it works with all the engines (or specified subsets of engines), behaves as if it is working with a single engine.\n",
      "\n",
      "If you do not specify the engines when the `LoadBalancedView` is created, it will use all the engines that are available when it assigns tasks."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(10):\n",
      "    pid = lb_view.apply_sync(os.getpid)\n",
      "    print('Task {0} ran on process {1}'.format(i, pid))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Task 0 ran on process 47041\n",
        "Task 1 ran on process 47040\n",
        "Task 2 ran on process 47038\n",
        "Task 3 ran on process 47039\n",
        "Task 4 ran on process 47041\n",
        "Task 5 ran on process 47040\n",
        "Task 6 ran on process 47038\n",
        "Task 7 ran on process 47039"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Task 8 ran on process 47041\n",
        "Task 9 ran on process 47040\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "\n",
      "def abc(y, N, epsilon=[0.2, 0.8]):\n",
      "\n",
      "    trace = []\n",
      "\n",
      "    while len(trace) < N:\n",
      "\n",
      "        # Simulate from priors\n",
      "        mu = numpy.random.normal(0, 10)\n",
      "        sigma = numpy.random.uniform(0, 20)\n",
      "\n",
      "        x = numpy.random.normal(mu, sigma, 50)\n",
      "\n",
      "        #if (np.linalg.norm(y - x) < epsilon):\n",
      "        if ((abs(x.mean() - y.mean()) < epsilon[0]) &\n",
      "            (abs(x.std() - y.std()) < epsilon[1])):\n",
      "            trace.append([mu, sigma])\n",
      "\n",
      "    return trace"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tasks = lb_view.map_async(lambda n: abc(y, n), [100]*5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tasks.msg_ids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 58,
       "text": [
        "['eb6b0e54-5e55-42bb-b660-00dca79dab44',\n",
        " '330a4e6a-ac9e-4c78-81f0-3f3610013388',\n",
        " '6ba8aabb-2c52-4429-9087-db4e58ccebb3',\n",
        " 'f9507bd9-206c-4b46-8875-f1385a59ad9e',\n",
        " 'fdba7157-7d81-43e5-88a3-917f4b97fef5']"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = np.concatenate(tasks.get())\n",
      "result[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 59,
       "text": [
        "array([[ 2.86369023,  2.86554596],\n",
        "       [ 2.80496613,  2.80319329],\n",
        "       [ 3.06949492,  2.91586367],\n",
        "       [ 3.50076685,  1.56286927],\n",
        "       [ 4.14868804,  1.69562106],\n",
        "       [ 3.44306256,  1.42334125],\n",
        "       [ 3.68902077,  1.35501729],\n",
        "       [ 3.8568506 ,  1.33526173],\n",
        "       [ 3.83018402,  2.29608881],\n",
        "       [ 3.9224022 ,  2.04869499]])"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another way that you can dispatch tasks to engines is via the `parallel` decorator. This decorator is a method of the `DirectView` class that controls our engine pool. The decorated function is then disparched to the engines using the `map` method that the decorator adds to the class."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@lb_view.parallel(block=True)\n",
      "def abc(y, N, epsilon=[0.2, 0.8]):\n",
      "\n",
      "    trace = []\n",
      "\n",
      "    while len(trace) < N:\n",
      "\n",
      "        # Simulate from priors\n",
      "        mu = numpy.random.normal(0, 10)\n",
      "        sigma = numpy.random.uniform(0, 20)\n",
      "\n",
      "        x = numpy.random.normal(mu, sigma, 50)\n",
      "\n",
      "        #if (np.linalg.norm(y - x) < epsilon):\n",
      "        if ((abs(x.mean() - y.mean()) < epsilon[0]) &\n",
      "            (abs(x.std() - y.std()) < epsilon[1])):\n",
      "            trace.append([mu, sigma])\n",
      "\n",
      "    return trace"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "abc.map([y]*4, [100]*4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 61,
       "text": [
        "[[[3.4871153993129966, 2.501924746507691],\n",
        "  [3.52852227337844, 1.6948454083609676],\n",
        "  [3.560715408962431, 2.2500906587060943],\n",
        "  [3.7762555729462486, 1.7355661213572304],\n",
        "  [3.8572966398406567, 1.8226351651960249],\n",
        "  [3.6836441264584034, 1.2725467247211886],\n",
        "  [3.8034242792735418, 2.3871011881895],\n",
        "  [3.608352779809611, 2.8268460721119992],\n",
        "  [3.4351352301954607, 2.260509766336285],\n",
        "  [3.7226758580691115, 1.4626630471373514],\n",
        "  [3.831235406284014, 2.060052176433087],\n",
        "  [3.682280183896045, 2.693939300539545],\n",
        "  [3.9806597466819023, 2.317665676075975],\n",
        "  [3.018896067156904, 2.966149561252358],\n",
        "  [3.5732223779467294, 1.6805158855289792],\n",
        "  [3.161166479286912, 2.539820451230268],\n",
        "  [4.2158650450959385, 2.0838700302246593],\n",
        "  [3.5298717639875656, 2.7354464673339773],\n",
        "  [3.704790571216062, 1.3945498869261441],\n",
        "  [3.71915193276931, 2.796877445264554],\n",
        "  [3.483567074973717, 1.9224884137425424],\n",
        "  [3.6570067257252625, 2.367861338701267],\n",
        "  [3.550364953912716, 2.2584685637470003],\n",
        "  [3.179862617086431, 1.5553466811809247],\n",
        "  [3.440057805506701, 1.2374364778694091],\n",
        "  [3.4353768084519576, 1.593086639888932],\n",
        "  [4.060809479701785, 2.7966324547152577],\n",
        "  [4.034936160643219, 1.5459293023739051],\n",
        "  [3.6670982455790204, 1.265913385393882],\n",
        "  [3.77532076058304, 1.2057506473393276],\n",
        "  [3.5107434069732593, 2.891122647329165],\n",
        "  [3.642363473579728, 1.6065214301751207],\n",
        "  [3.201759778703969, 3.2313696593735997],\n",
        "  [3.3849129579193105, 1.699180754010392],\n",
        "  [3.658808579273454, 1.2581802113489982],\n",
        "  [3.6879946685731104, 2.2694269917311183],\n",
        "  [3.5767354684076835, 1.2830225789287364],\n",
        "  [3.2081602322651315, 1.5590727935964743],\n",
        "  [3.404228738197079, 2.3705019969753915],\n",
        "  [3.6446455073999267, 1.092290927888644],\n",
        "  [3.3785334891354006, 1.7955263147111356],\n",
        "  [3.5162488188098964, 2.1761485546288517],\n",
        "  [3.360851271000977, 2.1145916474598403],\n",
        "  [3.4448385799462966, 2.579216359316754],\n",
        "  [3.8919173008732084, 2.351008056245014],\n",
        "  [3.653314029155016, 1.5717299749045543],\n",
        "  [3.0756745566267134, 2.6276763397629566],\n",
        "  [3.20794646600785, 2.14624170459512],\n",
        "  [3.02844730345726, 3.0873077376505553],\n",
        "  [3.324359927372967, 2.1434931592205664],\n",
        "  [3.629978801898093, 1.9590923357264356],\n",
        "  [3.221832426686114, 2.280324339689459],\n",
        "  [3.5368629371970064, 1.1873736922005906],\n",
        "  [3.416710217460816, 2.0700608023842926],\n",
        "  [3.5787214124604128, 1.7116884229201923],\n",
        "  [4.051907671293655, 1.9631049006228185],\n",
        "  [3.294667161812132, 1.6566528616905263],\n",
        "  [3.8379633865440703, 2.2191296716484565],\n",
        "  [3.8417115045260184, 1.9892725684413626],\n",
        "  [3.4939724992269197, 2.6761836740853395],\n",
        "  [3.3872890496235786, 3.170095718177519],\n",
        "  [3.780232184474908, 1.3422308614150658],\n",
        "  [4.038966597291457, 2.598650764525361],\n",
        "  [3.4640720133788894, 1.4402713743736584],\n",
        "  [3.4951115093803504, 1.5853372127467957],\n",
        "  [2.970122123259236, 2.175210091743638],\n",
        "  [3.751059369213684, 1.6059516814385866],\n",
        "  [3.806555073024774, 1.922277113886477],\n",
        "  [3.574922198636295, 2.1576842298257626],\n",
        "  [3.3868392996932335, 2.202672014948235],\n",
        "  [3.561204683560488, 2.9396812723110233],\n",
        "  [3.723435991621897, 1.9936742064359825],\n",
        "  [3.6154960550713477, 2.589814446748784],\n",
        "  [3.4288630748294913, 1.3024607040639191],\n",
        "  [3.199190697470722, 2.3321933698958586],\n",
        "  [3.5266441821885253, 1.8606845412746265],\n",
        "  [3.9166896487897502, 1.970459922271064],\n",
        "  [3.4664827955858293, 1.6421018505687712],\n",
        "  [3.6678696276147704, 1.436801997447854],\n",
        "  [3.543462692933865, 1.011945544404973],\n",
        "  [3.7326840667720966, 1.13796146890351],\n",
        "  [3.3325521758839294, 2.4077373968146087],\n",
        "  [3.5004014897560483, 1.2098675196496855],\n",
        "  [3.547392147922257, 1.6602010009309232],\n",
        "  [3.535367956918482, 1.7848074679682124],\n",
        "  [3.262539374226827, 2.4325149737942864],\n",
        "  [3.377730538725055, 2.450256046238164],\n",
        "  [3.5289538356900474, 1.708015761834214],\n",
        "  [3.8671829917028813, 2.205533434842708],\n",
        "  [3.8167135006438007, 2.0889384723092275],\n",
        "  [3.2581330938772575, 1.9850558182884304],\n",
        "  [4.134727421616896, 2.171565819068828],\n",
        "  [3.295510175942382, 1.3632926469187634],\n",
        "  [3.532493504305964, 2.758651068392295],\n",
        "  [3.5657930399864277, 1.942430269372537],\n",
        "  [3.258139925835368, 2.8834164423470243],\n",
        "  [3.383285618216536, 1.961129679178777],\n",
        "  [3.232047396532021, 2.3118344598516427],\n",
        "  [3.978557296035029, 1.3335314115365438],\n",
        "  [3.4097837234878536, 1.414633484310459]],\n",
        " [[3.6598945893521986, 2.816348277283751],\n",
        "  [3.992127519676711, 2.6389591170607463],\n",
        "  [2.9619509380287496, 2.4208571231341747],\n",
        "  [4.545539000517804, 3.573674107108298],\n",
        "  [3.7283367326756016, 2.4943904351162094],\n",
        "  [4.01386806081022, 1.5872296276697218],\n",
        "  [3.9353982160665355, 1.4777572058441102],\n",
        "  [3.820566608759246, 2.4231141647295806],\n",
        "  [3.8519889339932845, 2.51784951930913],\n",
        "  [3.545148299071885, 1.4256710152484309],\n",
        "  [3.5454670456059967, 1.438046912682418],\n",
        "  [3.1321301217394204, 2.347994547575736],\n",
        "  [3.370307152948376, 1.52151181422167],\n",
        "  [4.197769737506316, 2.8900983981611783],\n",
        "  [3.3838481632208457, 2.63476670573906],\n",
        "  [3.1827729639543096, 1.3329238322438575],\n",
        "  [3.363479881973373, 2.62809560191418],\n",
        "  [3.596205395366934, 1.5964058297223005],\n",
        "  [3.9821749368855897, 1.320016297776736],\n",
        "  [3.732155526308771, 1.357469567422589],\n",
        "  [3.5427980916946034, 1.663039801079993],\n",
        "  [3.3296892258451036, 2.4994119416716765],\n",
        "  [3.5916960974739407, 2.306475503723513],\n",
        "  [3.427920921774973, 2.480047312666165],\n",
        "  [3.940441636890623, 2.623996312933692],\n",
        "  [3.4067791663742857, 1.954216417739223],\n",
        "  [3.6857615806103983, 2.7368922257286243],\n",
        "  [3.2390469950957095, 2.0136811996911064],\n",
        "  [3.577000027880745, 2.5137492623887847],\n",
        "  [3.2947914772556484, 1.8365871807091771],\n",
        "  [3.2585837328223697, 2.028853501448369],\n",
        "  [2.89233216158044, 2.678084444658928],\n",
        "  [3.9634027266100396, 1.3528135274478714],\n",
        "  [3.4360938205761182, 2.2981942417834578],\n",
        "  [3.687862080131694, 1.482625989494839],\n",
        "  [3.888110500586426, 1.7009891411259592],\n",
        "  [2.8012765780575077, 2.589637644033025],\n",
        "  [3.4492491349059797, 1.8692165031931984],\n",
        "  [3.5670326217533765, 1.4648881206137854],\n",
        "  [3.3468124861564963, 2.1750134412757682],\n",
        "  [3.2440586116075094, 2.1424740157438316],\n",
        "  [3.555392032721225, 2.111533050648413],\n",
        "  [2.854021513678109, 2.1625901412037174],\n",
        "  [3.470612118852854, 2.2279146360397006],\n",
        "  [3.79940578972634, 1.3632781118975834],\n",
        "  [3.6866377428139847, 2.05480552463704],\n",
        "  [4.2060875271443185, 1.5132749380073163],\n",
        "  [3.983227344471848, 2.7380706613195915],\n",
        "  [3.595434054376556, 1.6500612323001485],\n",
        "  [3.271213571827415, 2.854073471345082],\n",
        "  [3.683893967143423, 1.6575279602386361],\n",
        "  [3.2740655958070795, 1.479692044858869],\n",
        "  [3.8384878019883932, 2.3875391854454664],\n",
        "  [3.4945165685270023, 2.8367003670691093],\n",
        "  [2.8739014375272776, 2.6369289748379976],\n",
        "  [3.818946332643052, 1.4737576517063689],\n",
        "  [3.325382715386495, 2.7787320094005286],\n",
        "  [3.780014726526174, 2.0074376342024647],\n",
        "  [3.184253484896536, 1.5556166250458303],\n",
        "  [3.4145963432339324, 1.4266895296240567],\n",
        "  [3.1154837060610463, 2.463374256581381],\n",
        "  [3.115385796889, 2.8424453371425717],\n",
        "  [3.4701918971935446, 1.9192240306459118],\n",
        "  [3.2955462051143547, 1.6547119104019736],\n",
        "  [3.4131792269668395, 2.545457117422787],\n",
        "  [3.6272513879425694, 1.9066284382712162],\n",
        "  [3.402156288066772, 1.8618585346216165],\n",
        "  [2.817251603064167, 2.8668515733447664],\n",
        "  [3.669589066777621, 1.8702131724091253],\n",
        "  [3.2169677801685492, 2.1643493211393428],\n",
        "  [3.656594197162357, 2.477149289295053],\n",
        "  [3.1617864669349953, 1.7078135558977103],\n",
        "  [3.6687238450250588, 1.1870696766191369],\n",
        "  [3.254873712635039, 1.4558438149984454],\n",
        "  [4.5668468500344765, 2.402813719698653],\n",
        "  [3.5187218493103325, 1.288114019125861],\n",
        "  [4.0832931913335715, 1.3489133632584216],\n",
        "  [3.632909296807934, 2.5621266375529927],\n",
        "  [2.808191917352041, 1.9776576041335825],\n",
        "  [3.18457816505445, 2.07645959848773],\n",
        "  [3.2969210787736625, 2.7537268594233133],\n",
        "  [3.437708903106474, 1.6498294634623267],\n",
        "  [3.3736127834788334, 2.6233385938350584],\n",
        "  [3.614474167693894, 2.037260864431194],\n",
        "  [3.479545192712977, 1.2179876699624037],\n",
        "  [3.3421754422226577, 2.172502285971114],\n",
        "  [3.749736215692074, 1.5037233747660617],\n",
        "  [3.5284709664440825, 1.0520047749887307],\n",
        "  [4.093715890011505, 2.827287187702374],\n",
        "  [3.439614860660005, 1.9142632388254865],\n",
        "  [3.2573600523074555, 2.3386946706130707],\n",
        "  [3.9153296508973683, 2.95400089334678],\n",
        "  [3.657161728267088, 2.002025995980854],\n",
        "  [3.3801120215917138, 1.4382603799209637],\n",
        "  [3.542964136954869, 1.686329280383343],\n",
        "  [3.721822112111779, 1.8589003742015375],\n",
        "  [4.2401150377510435, 2.284970518664531],\n",
        "  [3.3513027757850327, 2.622661185368309],\n",
        "  [3.7974609841492724, 2.0363240384889614],\n",
        "  [3.5286614712911795, 1.8614614302205323]],\n",
        " [[4.13233756855467, 2.502629388613964],\n",
        "  [3.164988395115614, 2.5234053228795683],\n",
        "  [3.396752634047926, 1.8230056640432712],\n",
        "  [3.687507471560018, 1.9250663699014514],\n",
        "  [3.7127760021686935, 2.528485484493239],\n",
        "  [2.9785954761791924, 3.127105512456978],\n",
        "  [3.804165318522323, 1.461527551188344],\n",
        "  [3.127708572528007, 2.3628098179052426],\n",
        "  [3.8449406879699066, 2.375521113517418],\n",
        "  [3.640267665521955, 1.9587169322434295],\n",
        "  [3.6806738435703874, 2.2764663180745126],\n",
        "  [4.066192200489075, 1.688694633708192],\n",
        "  [3.3096374417763252, 1.9135576400066734],\n",
        "  [3.2205915814173904, 1.495978446468862],\n",
        "  [3.434894794747196, 2.5269989337036547],\n",
        "  [3.5955280466618063, 1.7902097956870522],\n",
        "  [3.5992746124836383, 1.8510392594764524],\n",
        "  [3.807300399183697, 2.4493611878885146],\n",
        "  [2.729669495443616, 2.811802700516035],\n",
        "  [3.7231958897150887, 1.194241836886325],\n",
        "  [4.038176954699265, 2.8120585014378574],\n",
        "  [3.9007177251988994, 2.1480932638892147],\n",
        "  [3.649088199049253, 1.8906380555608537],\n",
        "  [3.420314233603537, 2.329746068319729],\n",
        "  [3.6964322027779364, 1.1053703171454643],\n",
        "  [3.043309173017704, 2.55061443411827],\n",
        "  [4.272498819969906, 2.5430192058053946],\n",
        "  [3.609312041280118, 3.032450164492251],\n",
        "  [3.642891935160063, 1.7438676758347782],\n",
        "  [3.206163012195516, 2.4318982920105126],\n",
        "  [3.2058909401385667, 1.2631405310687338],\n",
        "  [3.5570295500207956, 2.1735942419621046],\n",
        "  [4.011836749037421, 1.363586972420181],\n",
        "  [4.117344374307629, 1.8873033086361102],\n",
        "  [3.5205806819588723, 1.2962369434140308],\n",
        "  [3.530100685528204, 2.4047719627302833],\n",
        "  [3.777425022009373, 1.3659152240521588],\n",
        "  [3.193704711127044, 1.9928194766912632],\n",
        "  [3.3143102072563364, 2.781544215932592],\n",
        "  [3.6916001403209946, 1.2938310319455049],\n",
        "  [3.7404529916144735, 1.679673186340609],\n",
        "  [3.71155488610872, 2.612300677601904],\n",
        "  [3.94495717831151, 2.716292314195583],\n",
        "  [3.138221616300694, 1.9410402118680525],\n",
        "  [3.1188901069279047, 2.4512974696800782],\n",
        "  [3.194223458611219, 2.7878936497185314],\n",
        "  [3.407520049568345, 1.370782351918145],\n",
        "  [3.3098083728083743, 1.646036501420749],\n",
        "  [3.2543882528993766, 1.168536885660485],\n",
        "  [3.8728926923122424, 3.248635857468365],\n",
        "  [3.767271156887607, 1.4724581859489283],\n",
        "  [3.6646006008120224, 1.7808255170148568],\n",
        "  [3.8964903713816823, 1.3492393945819847],\n",
        "  [3.604376198775059, 1.086140779263094],\n",
        "  [4.217676503303784, 2.474853147187126],\n",
        "  [2.64824547232989, 1.998326032168356],\n",
        "  [3.7428060099563454, 1.6700572719090623],\n",
        "  [3.09844802858871, 1.5340735521737536],\n",
        "  [3.05741862223944, 1.8993939999849618],\n",
        "  [3.6862598966375315, 2.063835261164577],\n",
        "  [3.5591510915112803, 1.5199382591819144],\n",
        "  [3.4370608518793375, 3.1256897115854954],\n",
        "  [4.039557836915652, 1.9053175427983016],\n",
        "  [3.581294048963486, 1.7691157401091706],\n",
        "  [3.8908069315901237, 2.765958081465645],\n",
        "  [3.0739974153791074, 1.8560714893225772],\n",
        "  [3.8173471741079297, 2.1218424849977424],\n",
        "  [3.724379195689899, 3.2632737694300773],\n",
        "  [3.430244380649557, 1.4241735149491541],\n",
        "  [3.165775805878433, 2.248656320219795],\n",
        "  [3.6334187696836953, 1.9288055332710718],\n",
        "  [3.329785746017659, 1.7240116976442899],\n",
        "  [3.4074165482166046, 3.0236437848765063],\n",
        "  [4.24334578292889, 2.7833011466174007],\n",
        "  [3.9229519686820202, 1.6744898284620047],\n",
        "  [3.541656157359867, 2.5426697852861135],\n",
        "  [3.4781632271176615, 1.9850267212757422],\n",
        "  [3.4485124099528175, 1.9607650385964481],\n",
        "  [3.694627255362561, 2.7299937986420986],\n",
        "  [3.842008300595459, 2.5406910410991546],\n",
        "  [3.322813794003311, 1.8249928987152875],\n",
        "  [3.5478932131943015, 1.9654033264521997],\n",
        "  [3.2944834228384643, 2.635493253078993],\n",
        "  [3.7208550554068824, 1.310447797032388],\n",
        "  [3.26388034236829, 2.277538997864559],\n",
        "  [3.9471294144888254, 1.9448371106493845],\n",
        "  [4.956618897215517, 2.899955398195837],\n",
        "  [3.9267377918712656, 2.095837124175952],\n",
        "  [3.5674488534655815, 2.0298301931142615],\n",
        "  [3.5442659023098484, 1.6857191990531772],\n",
        "  [3.6887865187896667, 1.8842597223636814],\n",
        "  [3.727983335224019, 1.4921309347962142],\n",
        "  [3.4905081978347625, 2.1888812294526994],\n",
        "  [4.035581631643219, 1.467091386323962],\n",
        "  [3.262104054401667, 3.0660853904685603],\n",
        "  [3.125069264962274, 2.437862682720482],\n",
        "  [3.3890165302641284, 1.599306927419888],\n",
        "  [3.4184949698564138, 2.207615134511123],\n",
        "  [3.7059743533735423, 2.37134123047968],\n",
        "  [3.4216822881572244, 2.1492882454355478]],\n",
        " [[4.0552737874960005, 1.5712325061628052],\n",
        "  [3.432869784812618, 2.5367560403557765],\n",
        "  [3.195008511223837, 1.978941716799778],\n",
        "  [3.5075698218149345, 2.038032835503427],\n",
        "  [3.719565758366443, 1.1040139268142934],\n",
        "  [3.6203194754369052, 2.104010394768394],\n",
        "  [4.178681248831191, 1.8214949782373013],\n",
        "  [3.8554457744540387, 2.218036848292846],\n",
        "  [3.835052835890483, 2.1188788066521513],\n",
        "  [3.182103346866523, 2.2377567131593445],\n",
        "  [3.5050119955554555, 2.526364275557005],\n",
        "  [3.378421538473324, 1.6926460034005353],\n",
        "  [3.2368852262516112, 2.4364066309209775],\n",
        "  [3.4916904586243493, 2.769136667554095],\n",
        "  [2.549478441680975, 2.159382298021306],\n",
        "  [3.64755018100686, 1.961980878955567],\n",
        "  [4.161886072415263, 1.9066120196869263],\n",
        "  [3.220858800236379, 2.5179820027309807],\n",
        "  [3.06153352441965, 2.2563539720550763],\n",
        "  [4.111946782570643, 2.2458893370260524],\n",
        "  [3.5708676296977684, 1.053953684370057],\n",
        "  [2.9551445360217454, 2.6185488733690465],\n",
        "  [3.6603331451730496, 1.419035890386624],\n",
        "  [3.8071381113915255, 2.4167232866625765],\n",
        "  [2.9386521163085173, 2.252338730791794],\n",
        "  [3.493929659374756, 1.403070671764406],\n",
        "  [3.170223028339714, 2.5257123762732347],\n",
        "  [3.8112391453839023, 2.0876934107527667],\n",
        "  [3.8934038255946177, 3.068547864649107],\n",
        "  [3.2964261083815574, 2.2237274272697083],\n",
        "  [2.9790673817919155, 1.224385909568524],\n",
        "  [3.8878997906816566, 1.4087324161436698],\n",
        "  [3.2639507800932077, 2.0069947168846047],\n",
        "  [2.7201621822501307, 2.6679419752359523],\n",
        "  [3.7201097769745783, 1.9018393942205525],\n",
        "  [3.648348549174727, 2.039666382897729],\n",
        "  [3.912120946982251, 2.052180910245045],\n",
        "  [3.886408033154745, 1.9025201399575598],\n",
        "  [3.4969456277234157, 2.15932180866945],\n",
        "  [3.610665917985403, 2.1137097931396975],\n",
        "  [3.459643445822724, 1.9059511162126763],\n",
        "  [3.394864476447086, 1.262322224263952],\n",
        "  [4.296516804695637, 2.476495123916176],\n",
        "  [3.1948226269452, 2.199119617507561],\n",
        "  [3.20582822987952, 1.4919632911771963],\n",
        "  [4.034916485772651, 1.175112914957348],\n",
        "  [3.397994922919138, 2.220973814295637],\n",
        "  [4.028774720542904, 1.3217540029275598],\n",
        "  [3.575476600849528, 1.8628397807571084],\n",
        "  [2.8324392481105845, 2.39344552079064],\n",
        "  [3.8175377885417348, 3.1342562899939175],\n",
        "  [3.774136470888079, 2.5738165197058827],\n",
        "  [3.425780981594211, 1.463502974081523],\n",
        "  [3.815056536226043, 1.523227210316136],\n",
        "  [3.474730238944868, 2.4413818622301586],\n",
        "  [3.6996330773198083, 1.6890285774472202],\n",
        "  [3.648567706482474, 1.2685882800331627],\n",
        "  [3.394516503373399, 2.381048087842106],\n",
        "  [3.846407350315099, 1.091536319578592],\n",
        "  [3.316740083984775, 1.4234357496986916],\n",
        "  [4.053657138645187, 1.4428078967907054],\n",
        "  [3.763679465386425, 2.6038240883122565],\n",
        "  [3.3369818752815754, 1.101488286637069],\n",
        "  [3.050920991085281, 1.4505475875384866],\n",
        "  [3.756660399647198, 1.6240397717635147],\n",
        "  [3.509053985355428, 2.733179008083806],\n",
        "  [2.947639399377314, 2.32432507198977],\n",
        "  [3.4843947259958794, 1.9424591558442272],\n",
        "  [3.826279022132409, 2.3238053619078847],\n",
        "  [3.5514978253330765, 1.9715038357816916],\n",
        "  [3.5416351296082453, 2.1965954266400622],\n",
        "  [3.9078367330954915, 2.52608671563181],\n",
        "  [3.543688920939827, 1.6915824320905126],\n",
        "  [3.421352721220738, 2.304029946368975],\n",
        "  [3.552149689855877, 2.523688427175532],\n",
        "  [3.1715736357766304, 2.7140472940691596],\n",
        "  [3.8309380263554815, 1.7508928631136733],\n",
        "  [3.9915976540348352, 1.7827428427265324],\n",
        "  [3.597479172344491, 1.2007563910648678],\n",
        "  [3.937328638249907, 3.4140785534096407],\n",
        "  [3.9800762488530124, 1.348421182582098],\n",
        "  [3.0409686302017365, 2.0496004689170544],\n",
        "  [3.1237672692069025, 2.884395336178567],\n",
        "  [3.6607318793878383, 2.378245590155379],\n",
        "  [3.477511116483132, 1.8684195635517797],\n",
        "  [3.762094330338152, 0.9775287123541854],\n",
        "  [3.504097006692972, 1.4679658382787797],\n",
        "  [3.5646455993550665, 2.5828506954914965],\n",
        "  [3.679428633810522, 2.300372054087836],\n",
        "  [3.1139831272616525, 3.019044733228673],\n",
        "  [3.370139839212502, 2.358628421265694],\n",
        "  [3.492297819912793, 2.581356104080468],\n",
        "  [3.180722993599418, 2.615104587844743],\n",
        "  [3.5373822491949007, 2.6044176220215354],\n",
        "  [3.829581240064728, 1.5693361739256573],\n",
        "  [3.6712435169216597, 2.4890721433081864],\n",
        "  [3.776360936382448, 1.5805505370988282],\n",
        "  [3.4681943646744795, 1.4720540840550966],\n",
        "  [3.402494738708772, 2.4446650914541945],\n",
        "  [3.1476884944738703, 2.6240867103860466]]]"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Parallel magics\n",
      "\n",
      "The `%px` cell magic is a \"parallel execution\" statement, which will run the code in that cell on all the engines."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px \n",
      "import os\n",
      "print(os.getpid())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[stdout:0] 47038\n",
        "[stdout:1] 47039\n",
        "[stdout:2] 47040\n",
        "[stdout:3] 47041\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%px b = numpy.random.random()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%px b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[0:5]: \u001b[0m0.9697499713121036"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[1:5]: \u001b[0m0.32567200091393556"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[2:5]: \u001b[0m0.25346598383436025"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[3:5]: \u001b[0m0.15047237280019665"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`%pxresult` displays the output of the last request:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pxresult"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[0:5]: \u001b[0m0.9697499713121036"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[1:5]: \u001b[0m0.32567200091393556"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[2:5]: \u001b[0m0.25346598383436025"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[3:5]: \u001b[0m0.15047237280019665"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `%pxconfig` magic allows you to configure blocking for the parallel magics."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Switch to asynchronous\n",
      "%pxconfig --block"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Remember that each engine is just another IPython, so anyting you can do in an IPython session you can also do on an engine."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%px %pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[stdout:0] Populating the interactive namespace from numpy and matplotlib\n",
        "[stdout:1] Populating the interactive namespace from numpy and matplotlib\n",
        "[stdout:2] Populating the interactive namespace from numpy and matplotlib\n",
        "[stdout:3] Populating the interactive namespace from numpy and matplotlib\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[stderr:0] \n",
        "WARNING: pylab import has clobbered these variables: ['bar']\n",
        "`%pylab --no-import-all` prevents importing * from pylab and numpy\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%px samples = abc(y, 100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px \n",
      "import os\n",
      "tsamples = numpy.transpose(samples)\n",
      "plt.hist(tsamples[0])\n",
      "plt.hist(tsamples[1])\n",
      "_ = title('PID %i' % os.getpid())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "[output:0]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAENCAYAAADwjPVkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngEEIdQAwCKEOAAYh1AHAIIQ6ABjk/wFz38YHXP+LFgAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10a644d90>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "[output:1]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAENCAYAAADwjPVkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6gBgkP8DkGfKkCPRYbAAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10ddacdd0>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "[output:2]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAENCAYAAADwjPVkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x1096d1d90>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "[output:3]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAENCAYAAADwjPVkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndQAwCKEOAAYh1AHAIIQ6ABjk/wCSkPiyY14d8wAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x1112b2dd0>"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For profiling, we can also use the `%timeit` magic to compare performance on the engines:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "%%timeit\n",
      "s = abc(y, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[stdout:0] 1 loops, best of 3: 1.91 s per loop\n",
        "[stdout:1] 1 loops, best of 3: 2.35 s per loop\n",
        "[stdout:2] 1 loops, best of 3: 1.28 s per loop\n",
        "[stdout:3] 1 loops, best of 3: 1.92 s per loop\n"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Cython Parallel\n",
      "\n",
      "In order to use Cython in parallel on IPython, we need to load and execute `cythonmagic` on all engines."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%px %load_ext cythonmagic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As an example, let's use the Cythonized Gibbs sampler from the last lecture."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "%%cython\n",
      "\n",
      "from numpy import zeros, random\n",
      "from numpy cimport *\n",
      "from libc.math cimport sqrt\n",
      "gamma = random.gamma\n",
      "normal = random.normal\n",
      "\n",
      "def gibbs(int N=20000, int thin=200):\n",
      "    cdef: \n",
      "        ndarray[float64_t, ndim=2] mat = zeros((N,2))\n",
      "        float64_t x,y = 0\n",
      "        int i,j\n",
      "    for i in range(N):\n",
      "        for j in range(thin):\n",
      "            x = gamma(3, y**2 + 4)\n",
      "            y = normal(1./(x+1), 1./sqrt(2*(x+1)))\n",
      "        mat[i] = x,y\n",
      "\n",
      "    return mat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Divide the array by the number of nodes.  In this case they divide evenly, a more general partitioning of sizes is easy to do as well."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cli.ids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 73,
       "text": [
        "[0, 1, 2, 3]"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N = 100000\n",
      "thin = 10\n",
      "n = N/len(cli.ids)\n",
      "dv = cli[:]\n",
      "dv.push(dict(n=n, thin=thin))\n",
      "# Let's just confirm visually we got what we expect\n",
      "dv['n']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 74,
       "text": [
        "[25000, 25000, 25000, 25000]"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can time the execution of the gibbs sampler on the remote nodes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pxconfig --noblock"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit dv.execute('gibbs(n, thin)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100 loops, best of 3: 4.43 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But a more realistic (and costly) benchmark must also include the cost of bringing the results back from the cluster engines to our local namespace.  For that, we assign the call to the variable `a` on each node and then use the view's `gather` method to pull them back in:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "dv.execute('a = gibbs(n, thin)')\n",
      "a = dv.gather('a')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<AsyncMapResult: gather>\n",
        "<AsyncMapResult: gather>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "100 loops, best of 3: 28.2 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's compare this to the same number of samples executed on a single process:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext cythonmagic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cython\n",
      "\n",
      "from libc.math cimport sqrt\n",
      "from numpy import zeros, random\n",
      "from numpy cimport *\n",
      "gamma = random.gamma\n",
      "normal = random.normal\n",
      "\n",
      "def gibbs(int N=20000, int thin=200):\n",
      "    cdef: \n",
      "        ndarray[float64_t, ndim=2] mat = zeros((N,2))\n",
      "        float64_t x,y = 0\n",
      "        int i,j\n",
      "    for i in range(N):\n",
      "        for j in range(thin):\n",
      "            x = gamma(3, y**2 + 4)\n",
      "            y = normal(1./(x+1), 1./sqrt(2*(x+1)))\n",
      "        mat[i] = x,y\n",
      "\n",
      "    return mat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit \n",
      "a = gibbs(N, thin)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 1.63 s per loop\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise\n",
      "\n",
      "Run parallel chains of the `disaster_model` example from PyMC and return the resulting traces to your client, for plotting and summarization."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Write your answer here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## References\n",
      "\n",
      "[Scientific Python Lectures](http://github.com/jrjohansson/scientific-python-lectures) by Robert Johansson\n",
      "\n",
      "[Using IPython for Parallel Computing](http://ipython.org/ipython-doc/dev/parallel/)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML\n",
      "def css_styling():\n",
      "    styles = open(\"styles/custom.css\", \"r\").read()\n",
      "    return HTML(styles)\n",
      "css_styling()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<style>\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
        "    }\n",
        "    div.cell{\n",
        "        width:800px;\n",
        "/*        margin-left:16% !important;*/\n",
        "        margin-left:auto;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    h1 {\n",
        "        font-family: Helvetica, serif;\n",
        "    }\n",
        "    h4{\n",
        "        margin-top:12px;\n",
        "        margin-bottom: 3px;\n",
        "       }\n",
        "    div.text_cell_render{\n",
        "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
        "        line-height: 145%;\n",
        "        font-size: 130%;\n",
        "        width:800px;\n",
        "        margin-left:auto;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    .CodeMirror{\n",
        "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
        "    }\n",
        "/*    .prompt{\n",
        "        display: None;\n",
        "    }*/\n",
        "    .text_cell_render h5 {\n",
        "        font-weight: 300;\n",
        "        font-size: 16pt;\n",
        "        color: #4057A1;\n",
        "        font-style: italic;\n",
        "        margin-bottom: .5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\n",
        "\n",
        "    .warning{\n",
        "        color: rgb( 240, 20, 20 )\n",
        "        }\n",
        "</style>\n",
        "<script>\n",
        "    MathJax.Hub.Config({\n",
        "                        TeX: {\n",
        "                           extensions: [\"AMSmath.js\"]\n",
        "                           },\n",
        "                tex2jax: {\n",
        "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
        "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
        "                },\n",
        "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
        "                \"HTML-CSS\": {\n",
        "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
        "                }\n",
        "        });\n",
        "</script>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<IPython.core.display.HTML at 0x10f9b0dd0>"
       ]
      }
     ],
     "prompt_number": 1
    }
   ],
   "metadata": {}
  }
 ]
}